{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from matplotlib.cbook import MatplotlibDeprecationWarning\n",
    "warnings.simplefilter('ignore', MatplotlibDeprecationWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "warnings.simplefilter('ignore', RuntimeWarning)\n",
    "warnings.simplefilter('ignore',UnicodeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "![HELP logo](https://github.com/pdh21/FIR_bootcamp_2016/blob/master/Figures/Help_Logo.png?raw=true)\n",
    "# XID+\n",
    "### _Peter Hurley_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Uses a MCMC based approach to get FULL posterior\n",
    "2. Provide a natural framework to introduce additional prior information\n",
    "3. Allows more accurate estimate of flux density errors for each source\n",
    "4. Provides a platform for doing science with the maps (e.g Hierarchical stacking of LBGs, Luminosity function from the map etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![stan logo](https://github.com/stan-dev/logos/blob/master/pystan_logo_name.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Cross-identification tends to be done with catalogues, then science with the matched catalogues.\n",
    "\n",
    "XID+ takes a different philosophy.\n",
    "* Catalogues are a form of data compression. OK in some cases, not so much in others: \n",
    "    - i.e. confused images: catalogue compression loses correlation information\n",
    "* Ideally, science should be done without compression..\n",
    "\n",
    "XID+ provides a framework to cross identify galaxies we know about in different maps, with the idea that it can be extended to do science with the maps!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilistic Framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Philosophy: \n",
    "* build a probabilistic generative model for the SPIRE maps\n",
    "* Infer model on SPIRE maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Bayes Theorem\n",
    "$p(\\mathbf{f}|\\mathbf{d}) \\propto p(\\mathbf{d}|\\mathbf{f}) \\times p(\\mathbf{f})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generative Model\n",
    "In order to carry out Bayesian inference, we need a model to carry out inference on.\n",
    "\n",
    "For the SPIRE maps, our model is quite simple, with likelihood defined as:\n",
    "    $L = p(\\mathbf{d}|\\mathbf{f}) \\propto |\\mathbf{N_d}|^{-1/2} \\exp\\big\\{ -\\frac{1}{2}(\\mathbf{d}-\\mathbf{Af})^T\\mathbf{N_d}^{-1}(\\mathbf{d}-\\mathbf{Af})\\big\\}$\n",
    "\n",
    "where:\n",
    "    $\\mathbf{N_{d,ii}} =\\sigma_{inst.,ii}^2+\\sigma_{conf.}^2$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Simplest model for XID+ assumes following:\n",
    "* All sources are known and have positive flux (fi)\n",
    "* A global background (B) contributes to all pixels \n",
    "* PRF is fixed and known\n",
    "* Confusion noise is constant and not correlated across pixels\n",
    "---\n",
    "Because we are getting the joint probability distribution, our model is generative:\n",
    "    \n",
    "* Given parameters, we generate data and vica-versa\n",
    "    \n",
    "Compared to discriminative model (i.e. neural network), which only obtains conditional probability distribution:\n",
    "\n",
    "* Neural network, give inputs, get output. Can't go other way'\n",
    "\n",
    "Generative model is full probabilistic model. Allows more complex relationships between observed and target variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XID+ in action\n",
    "XID+ applied to GALFORM simulation of COSMOS field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lets look at part of COSMOS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Fit to Lacey GALFORM\n",
    "* SAM simulation (with dust) ran through SMAP pipeline_ similar depth and size as COSMOS\n",
    "* Used galaxies with an observed 100 micron flux of gt. $50\\mathbf{\\mu Jy}$. Gives 64823\n",
    "* used tiles of 0.2 degrees with buffer.\n",
    "* Uninformative prior: uniform in log space $10^{-8} - 10{^3} \\mathbf{mJy}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN SCRIPT\n",
    "======================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import ascii, fits\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "from astropy import wcs\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xidplus\n",
    "from xidplus import moc_routines\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set image and catalogue filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Folder containing maps\n",
    "imfolder=xidplus.__path__[0]+'/../test_files/'\n",
    "\n",
    "pswfits=imfolder+'cosmos_itermap_lacey_07012015_simulated_observation_w_noise_PSW_hipe.fits.gz'#SPIRE 250 map\n",
    "pmwfits=imfolder+'cosmos_itermap_lacey_07012015_simulated_observation_w_noise_PMW_hipe.fits.gz'#SPIRE 350 map\n",
    "plwfits=imfolder+'cosmos_itermap_lacey_07012015_simulated_observation_w_noise_PLW_hipe.fits.gz'#SPIRE 500 map\n",
    "\n",
    "\n",
    "#Folder containing prior input catalogue\n",
    "catfolder=xidplus.__path__[0]+'/../test_files/'\n",
    "#prior catalogue\n",
    "prior_cat='lacey_07012015_MillGas.ALLVOLS_cat_PSW_COSMOS_test.fits'\n",
    "\n",
    "\n",
    "#output folder\n",
    "output_folder='./'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in images, noise maps, header info and WCS information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----250-------------\n",
    "hdulist = fits.open(pswfits)\n",
    "im250phdu=hdulist[0].header\n",
    "im250hdu=hdulist[1].header\n",
    "\n",
    "im250=hdulist[1].data*1.0E3\n",
    "nim250=hdulist[2].data*1.0E3\n",
    "w_250 = wcs.WCS(hdulist[1].header)\n",
    "pixsize250=3600.0*w_250.wcs.cd[1,1] #pixel size (in arcseconds)\n",
    "hdulist.close()\n",
    "#-----350-------------\n",
    "hdulist = fits.open(pmwfits)\n",
    "im350phdu=hdulist[0].header\n",
    "im350hdu=hdulist[1].header\n",
    "\n",
    "im350=hdulist[1].data*1.0E3\n",
    "nim350=hdulist[2].data*1.0E3\n",
    "w_350 = wcs.WCS(hdulist[1].header)\n",
    "pixsize350=3600.0*w_350.wcs.cd[1,1] #pixel size (in arcseconds)\n",
    "hdulist.close()\n",
    "#-----500-------------\n",
    "hdulist = fits.open(plwfits)\n",
    "im500phdu=hdulist[0].header\n",
    "im500hdu=hdulist[1].header\n",
    "im500=hdulist[1].data*1.0E3\n",
    "nim500=hdulist[2].data*1.0E3\n",
    "w_500 = wcs.WCS(hdulist[1].header)\n",
    "pixsize500=3600.0*w_500.wcs.cd[1,1] #pixel size (in arcseconds)\n",
    "hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in catalogue you want to fit (and make any cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fits.open(catfolder+prior_cat)\n",
    "fcat=hdulist[1].data\n",
    "hdulist.close()\n",
    "inra=fcat['RA']\n",
    "indec=fcat['DEC']\n",
    "\n",
    "sgood=fcat['S100']>0.050\n",
    "\n",
    "inra=inra[sgood]\n",
    "indec=indec[sgood]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set prior classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---prior250--------\n",
    "prior250=xidplus.prior(im250,nim250,im250phdu,im250hdu)#Initialise with map, uncertianty map, wcs info and primary header\n",
    "prior250.prior_cat(inra,indec,prior_cat)#Set input catalogue\n",
    "prior250.prior_bkg(-5.0,5)#Set prior on background (assumes Guassian pdf with mu and sigma)\n",
    "#---prior350--------\n",
    "prior350=xidplus.prior(im350,nim350,im350phdu,im350hdu)\n",
    "prior350.prior_cat(inra,indec,prior_cat)\n",
    "prior350.prior_bkg(-5.0,5)\n",
    "\n",
    "#---prior500--------\n",
    "prior500=xidplus.prior(im500,nim500,im500phdu,im500hdu)\n",
    "prior500.prior_cat(inra,indec,prior_cat)\n",
    "prior500.prior_bkg(-5.0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pixsize array (size of pixels in arcseconds)\n",
    "pixsize=np.array([pixsize250,pixsize350,pixsize500])\n",
    "#point response function for the three bands\n",
    "prfsize=np.array([18.15,25.15,36.3])\n",
    "#use Gaussian2DKernel to create prf (requires stddev rather than fwhm hence pfwhm/2.355)\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "\n",
    "##---------fit using Gaussian beam-----------------------\n",
    "prf250=Gaussian2DKernel(prfsize[0]/2.355,x_size=101,y_size=101)\n",
    "prf250.normalize(mode='peak')\n",
    "prf350=Gaussian2DKernel(prfsize[1]/2.355,x_size=101,y_size=101)\n",
    "prf350.normalize(mode='peak')\n",
    "prf500=Gaussian2DKernel(prfsize[2]/2.355,x_size=101,y_size=101)\n",
    "prf500.normalize(mode='peak')\n",
    "\n",
    "pind250=np.arange(0,101,1)*1.0/pixsize[0] #get 250 scale in terms of pixel scale of map\n",
    "pind350=np.arange(0,101,1)*1.0/pixsize[1] #get 350 scale in terms of pixel scale of map\n",
    "pind500=np.arange(0,101,1)*1.0/pixsize[2] #get 500 scale in terms of pixel scale of map\n",
    "\n",
    "prior250.set_prf(prf250.array,pind250,pind250)#requires psf as 2d grid, and x and y bins for grid (in pixel scale)\n",
    "prior350.set_prf(prf350.array,pind350,pind350)\n",
    "prior500.set_prf(prf500.array,pind500,pind500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting 64824 sources \n",
      "\n",
      "using 1239145, 1239145 and 309801 pixels\n"
     ]
    }
   ],
   "source": [
    "print('fitting '+ str(prior250.nsrc)+' sources \\n')\n",
    "print('using ' +  str(prior250.snpix)+', '+ str(prior250.snpix)+' and '+ str(prior500.snpix)+' pixels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting this number of sources and datapoints is not practical. Suggest cutting down to a MOC based on a HEALPix tile with an order no greater than 10 for SPIRE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=10\n",
    "Tile=6977662\n",
    "moc=moc_routines.get_fitting_region(order,Tile)\n",
    "prior250.set_tile(moc)\n",
    "prior350.set_tile(moc)\n",
    "prior500.set_tile(moc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting 165 sources \n",
      "\n",
      "using 2656, 1378 and 664 pixels\n"
     ]
    }
   ],
   "source": [
    "print('fitting '+ str(prior250.nsrc)+' sources \\n')\n",
    "print('using ' +  str(prior250.snpix)+', '+ str(prior350.snpix)+' and '+ str(prior500.snpix)+' pixels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate pointing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior250.get_pointing_matrix()\n",
    "prior350.get_pointing_matrix()\n",
    "prior500.get_pointing_matrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default prior on flux is a uniform distribution, with a minimum and maximum of 0.01 and 1000.0 $\\mathrm{mJy}$ respectively for each source. running the function upper_lim _map resets the upper limit to the maximum flux value (plus a 5 sigma Background value) found in the map in which the source makes a contribution to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior250.upper_lim_map()\n",
    "prior350.upper_lim_map()\n",
    "prior500.upper_lim_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit using the interface to pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_d3ae8fe8977b50d1351c793d328f49e9 NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pdh21/Work/Astro/XID_plus/notebooks/examples/XID+SPIRE.pkl not found. Compiling\n"
     ]
    }
   ],
   "source": [
    "from xidplus.stan_fit import SPIRE\n",
    "fit=SPIRE.all_bands(prior250,prior350,prior500,iter=1500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the posterior class with the fit object from pystan, and save alongside the prior classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior=xidplus.posterior_stan(fit,[prior250,prior350,prior500])\n",
    "\n",
    "outfile=output_folder+'Tile_'+str(Tile)+'_'+str(order)+'_new.pkl'\n",
    "with open(outfile, 'wb') as f:\n",
    "    pickle.dump({'psw':prior250,'pmw':prior350,'plw':prior500,'posterior':posterior},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:new]",
   "language": "python",
   "name": "conda-env-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
