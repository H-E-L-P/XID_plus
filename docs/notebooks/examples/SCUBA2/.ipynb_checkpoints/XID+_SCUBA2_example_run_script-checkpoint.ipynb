{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# XID+ SCUBA-2 Example Run Script\n",
    "\n",
    "(This is based on a Jupyter notebook, available in the [XID+ package](https://github.com/H-E-L-P/XID_plus/tree/master/docs/notebooks/examples/) and can be interactively run and edited)\n",
    "\n",
    "XID+ is a probababilistic deblender for confusion dominated maps. It is designed to:\n",
    "\n",
    "1. Use a MCMC based approach to get FULL posterior\n",
    "2. Provide a natural framework to introduce additional prior information\n",
    "3. Allows more accurate estimate of flux density errors for each source\n",
    "4. Provides a platform for doing science with the maps (e.g XID+ Hierarchical stacking, Luminosity function from the map etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Cross-identification tends to be done with catalogues, then science with the matched catalogues.\n",
    "\n",
    "XID+ takes a different philosophy. Catalogues are a form of data compression. OK in some cases, not so much in others, i.e. confused images: catalogue compression loses correlation information. Ideally, science should be done without compression.\n",
    "\n",
    "XID+ provides a framework to cross identify galaxies we know about in different maps, with the idea that it can be extended to do science with the maps!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Philosophy: \n",
    "\n",
    "- build a probabilistic generative model for the SPIRE maps\n",
    "- Infer model on SPIRE maps\n",
    "\n",
    "Bayes Theorem\n",
    "\n",
    "$p(\\mathbf{f}|\\mathbf{d}) \\propto p(\\mathbf{d}|\\mathbf{f}) \\times p(\\mathbf{f})$\n",
    "\n",
    "In order to carry out Bayesian inference, we need a model to carry out inference on.\n",
    "\n",
    "For the SPIRE maps, our model is quite simple, with likelihood defined as:\n",
    "    $L = p(\\mathbf{d}|\\mathbf{f}) \\propto |\\mathbf{N_d}|^{-1/2} \\exp\\big\\{ -\\frac{1}{2}(\\mathbf{d}-\\mathbf{Af})^T\\mathbf{N_d}^{-1}(\\mathbf{d}-\\mathbf{Af})\\big\\}$\n",
    "\n",
    "where:\n",
    "    $\\mathbf{N_{d,ii}} =\\sigma_{inst.,ii}^2+\\sigma_{conf.}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Simplest model for XID+ assumes following:\n",
    "\n",
    "* All sources are known and have positive flux (fi)\n",
    "* A global background (B) contributes to all pixels \n",
    "* PRF is fixed and known\n",
    "* Confusion noise is constant and not correlated across pixels\n",
    "----\n",
    "Because we are getting the joint probability distribution, our model is generative:\n",
    "    \n",
    "* Given parameters, we generate data and vica-versa\n",
    "    \n",
    "Compared to discriminative model (i.e. neural network), which only obtains conditional probability distribution:\n",
    "\n",
    "* Neural network, give inputs, get output. Can't go other way'\n",
    "\n",
    "Generative model is full probabilistic model. Allows more complex relationships between observed and target variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  XID+ SCUBA2\n",
    "XID+ applied to example SCUBA-2 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Edit\n",
    "* SAM simulation (with dust) ran through SMAP pipeline_ similar depth and size as COSMOS\n",
    "* Use galaxies with an observed 100 micron flux of gt. $50\\mathbf{\\mu Jy}$. Gives 64823 sources\n",
    "* Uninformative prior: uniform $0 - 10{^3} \\mathbf{mJy}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: The mpl_toolkits.axes_grid module was deprecated in version 2.1. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist provies the same functionality instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/c/Users/spxmws/Documents/local-work/XID_plus/')\n",
    "\n",
    "from astropy.io import ascii, fits\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "from astropy import wcs\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xidplus\n",
    "from xidplus import moc_routines\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set image and catalogue filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/spxmws/Documents/local-work/XID_plus/xidplus'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xidplus.__path__[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set bands to run\n",
    "bands = {\"850\": True, \"450\":False}\n",
    "\n",
    "#Folder containing maps\n",
    "imfolder='/mnt/c/Users/spxmws/Documents/local-work/S2COSMOS/2016/'\n",
    "\n",
    "s850fits=imfolder+'COSMOS_all_2016-08-25_850_fcf_mf_crop.fits'# SCUBA-2 850 map\n",
    "s450fits=imfolder+'cosmos_itermap_lacey_07012015_simulated_observation_w_noise_PMW_hipe.fits.gz'# SCUBA-2 450 map\n",
    "\n",
    "# convert from SCUBA-2 format into standard fits\n",
    "convertMaps = False\n",
    "seperateErrMaps = True\n",
    "if seperateErrMaps:\n",
    "    s850ErrFits = imfolder+'COSMOS_all_2016-08-25_850_err_mf_crop.fits'\n",
    "    s450ErrFits = imfolder+''\n",
    "\n",
    "#Folder containing prior input catalogue\n",
    "catfolder=imfolder\n",
    "#prior catalogue\n",
    "prior_cat='COSMOS-testCat.fits'\n",
    "\n",
    "# matched filter\n",
    "matchedFilter = True\n",
    "\n",
    "#output folder\n",
    "output_folder=imfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in images, noise maps, header info and WCS information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----850-------------\n",
    "if bands[\"850\"]:\n",
    "    # open fits file\n",
    "    hdulist = fits.open(s850fits)\n",
    "    \n",
    "    ## if convert change file structure\n",
    "    if convertMaps:\n",
    "        # adjust data and header into 2D rather than 3D\n",
    "        header850 = hdulist[0].header\n",
    "        header850['NAXIS'] = 2\n",
    "        header850[\"i_naxis\"] = 2\n",
    "        del(header850['NAXIS3'])\n",
    "        del(header850[\"CRPIX3\"])\n",
    "        del(header850[\"CDELT3\"])\n",
    "        del(header850[\"CRVAL3\"])\n",
    "        del(header850[\"CTYPE3\"])\n",
    "        del(header850[\"LBOUND3\"])\n",
    "        del(header850[\"CUNIT3\"])\n",
    "\n",
    "        im850phdu=header850\n",
    "        im850hdu=header850\n",
    "\n",
    "        # convert variance to error\n",
    "        nim850 = np.sqrt(hdulist[1].data[0,:,:])\n",
    "\n",
    "        # convert units if needed\n",
    "        if im850hdu['BUNIT'] == 'mJy/beam':\n",
    "            im850 = hdulist[0].data[0,:,:]\n",
    "        elif im850hdu['BUNIT'] == 'mJy/arcsec**2':\n",
    "            im850=hdulist[0].data[0,:,:]*229.487\n",
    "            nim850=nim850.data*229.487\n",
    "        else:\n",
    "            raise Exception(\"Unit not Programmed\")\n",
    "\n",
    "        \n",
    "    else:\n",
    "        header850 = hdulist[0].header\n",
    "        im850phdu=header850\n",
    "        im850hdu=header850\n",
    "        \n",
    "        im850=hdulist[0].data\n",
    "        \n",
    "        if seperateErrMaps:\n",
    "            ehdulist = fits.open(s850ErrFits)\n",
    "            nim850=ehdulist[0].data\n",
    "            ehdulist.close()\n",
    "        else:\n",
    "            nim850=hdulist[1].data\n",
    "            ehdulist.close()\n",
    "\n",
    "    w_850 = wcs.WCS(im850hdu)\n",
    "    pixsizes850 = wcs.utils.proj_plane_pixel_scales(w_850)*3600.0\n",
    "    if np.abs(pixsizes850[0] - pixsizes850[1]) > 0.01:\n",
    "        raise Exception(\"Not programmed for Rectangular Pixels\")\n",
    "    pixsize850= pixsizes850[0]\n",
    "    hdulist.close()\n",
    "        \n",
    "#-----450-------------\n",
    "if bands[\"450\"]:\n",
    "    # open fits file\n",
    "    hdulist = fits.open(s450fits)\n",
    "    \n",
    "    ## if convert change file structure\n",
    "    if convertMaps:\n",
    "        # adjust data and header into 2D rather than 3D\n",
    "        header450 = hdulist[0].header\n",
    "        header450['NAXIS'] = 2\n",
    "        header450[\"i_naxis\"] = 2\n",
    "        del(header450['NAXIS3'])\n",
    "        del(header450[\"CRPIX3\"])\n",
    "        del(header450[\"CDELT3\"])\n",
    "        del(header450[\"CRVAL3\"])\n",
    "        del(header450[\"CTYPE3\"])\n",
    "        del(header450[\"LBOUND3\"])\n",
    "        del(header450[\"CUNIT3\"])\n",
    "\n",
    "        im450phdu=header450\n",
    "        im450hdu=header450\n",
    "\n",
    "        # convert variance to error\n",
    "        nim450 = np.sqrt(hdulist[1].data[0,:,:])\n",
    "\n",
    "        # convert units if needed\n",
    "        if im450hdu['BUNIT'] == 'mJy/beam':\n",
    "            im450 = hdulist[0].data[0,:,:]\n",
    "        elif im450hdu['BUNIT'] == 'mJy/arcsec**2':\n",
    "            im450=hdulist[0].data[0,:,:]*229.487\n",
    "            nim450=nim450.data*229.487\n",
    "        else:\n",
    "            raise Exception(\"Unit not Programmed\")\n",
    "\n",
    "        \n",
    "    else:\n",
    "        header450 = hdulist[0].header\n",
    "        im450phdu=header450\n",
    "        im450hdu=header450\n",
    "        \n",
    "        im450=hdulist[0].data\n",
    "        if seperateErrMaps:\n",
    "            ehdulist = fits.open(s450ErrFits)\n",
    "            nim450=ehdulist[0].data\n",
    "            ehdulist.close()\n",
    "        else:\n",
    "            nim450=hdulist[1].data\n",
    "            ehdulist.close()\n",
    "\n",
    "    w_450 = wcs.WCS(im850hdu)\n",
    "    pixsizes450 = wcs.utils.proj_plane_pixel_scales(w_450)*3600.0\n",
    "    if np.abs(pixsizes450[0] - pixsizes450[1]) > 0.01:\n",
    "        raise Exception(\"Not programmed for Rectangular Pixels\")\n",
    "    pixsize450= pixsizes450[0]\n",
    "    hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in catalogue you want to fit (and make any cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fits.open(catfolder+prior_cat)\n",
    "fcat=hdulist[1].data\n",
    "hdulist.close()\n",
    "inra=fcat['RA']\n",
    "indec=fcat['DEC']\n",
    "\n",
    "## select only sources with 100micron flux greater than 50 microJy\n",
    "#sgood=fcat['S100']>0.050\n",
    "#inra=inra[sgood]\n",
    "#indec=indec[sgood]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XID+ uses Multi Order Coverage (MOC) maps for cutting down maps and catalogues so they cover the same area. It can also take in MOCs as selection functions to carry out additional cuts. Lets use the python module [pymoc](http://pymoc.readthedocs.io/en/latest/) to create a MOC, centered on a specific position we are interested in. We will use a HEALPix order of 15 (the resolution: higher order means higher resolution), have a radius of 100 arcseconds centered around an R.A. of 150.74 degrees and Declination of 2.03 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5462521701032251 1.2488826600959155\n"
     ]
    }
   ],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "c = SkyCoord(ra=[150.00]*u.degree, dec=[2.5]*u.degree)  \n",
    "import pymoc\n",
    "moc=pymoc.util.catalog.catalog_to_moc(c,400,15)\n",
    "\n",
    "print(im850[1000,1000], nim850[1000,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XID+ is built around two python classes. A prior and posterior class. There should be a prior class for each map being fitted. It is initiated with a map, noise map, primary header and map header and can be set with a MOC. It also requires an input prior catalogue and point spread function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---prior850--------\n",
    "if bands[\"850\"]:\n",
    "    prior850=xidplus.prior(im850,nim850,im850phdu,im850hdu, moc=moc)#Initialise with map, uncertianty map, wcs info and primary header\n",
    "    prior850.prior_cat(inra,indec,prior_cat, moc=moc)#Set input catalogue\n",
    "    prior850.prior_bkg(-5.0,5)#Set prior on background (assumes Gaussian pdf with mu and sigma)\n",
    "\n",
    "#---prior450--------\n",
    "if bands[\"450\"]:\n",
    "    prior450=xidplus.prior(im450,nim450,im450phdu,im450hdu, moc=moc)\n",
    "    prior450.prior_cat(inra,indec,prior_cat, moc=moc)\n",
    "    prior450.prior_bkg(-5.0,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set PSF. For SPIRE, the PSF can be assumed to be Gaussian with a FWHM of 18.15, 25.15, 36.3 '' for 250, 350 and 500 $\\mathrm{\\mu m}$ respectively. Lets use the astropy module to construct a Gaussian PSF and assign it to the three XID+ prior classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Gaussian2DKernel to create prf (requires stddev rather than fwhm hence pfwhm/2.355)\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "\n",
    "#--- PSF 850 ---\n",
    "if bands[\"850\"]:\n",
    "    if matchedFilter:\n",
    "        prf850 = 41.4*Gaussian2DKernel(9.6,x_size=101,y_size=101) - 0.98*41.4*Gaussian2DKernel(1.00955*9.6,x_size=101,y_size=101)\n",
    "    else:\n",
    "        prf850 = 0.98*Gaussian2DKernel(13.0/2.355,x_size=101,y_size=101)+0.02*Gaussian2DKernel(48.0/2.355,x_size=101,y_size=101)\n",
    "    prf850.normalize(mode='peak')\n",
    "    \n",
    "    pind850=np.arange(0,101,1)*1.0/pixsize850 #get 850 scale in terms of pixel scale of m850\n",
    "    prior850.set_prf(prf850.array,pind850,pind850)#requires psf as 2d grid, and x and y bins for grid (in pixel scale)\n",
    "\n",
    "#--- PSF 450 ---\n",
    "if bands[\"450\"]:\n",
    "    if matchedFilter:\n",
    "        raise Exception(\"450 Match Filter not Programmed\")\n",
    "    else:\n",
    "        prf450 = 0.98*Gaussian2DKernel(13.0/2.355,x_size=101,y_size=101)+0.02*Gaussian2DKernel(48.0/2.355,x_size=101,y_size=101)\n",
    "    prf450.normalize(mode='peak')\n",
    "    \n",
    "    pind450=np.arange(0,101,1)*1.0/pixsize450 #get 450 scale in terms of pixel scale of m450\n",
    "    prior450.set_prf(prf450.array,pind450,pind450)#requires psf as 2d grid, and x and y bins for grid (in pixel scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850$\\mu$m band:\n",
      "\t fitting 60 sources \n",
      "\n",
      "\t using 125729 pixels\n"
     ]
    }
   ],
   "source": [
    "if bands[\"850\"]:\n",
    "    print(\"850$\\mu$m band:\")\n",
    "    print('\\t fitting '+ str(prior850.nsrc)+' sources \\n')\n",
    "    print('\\t using ' +  str(prior850.snpix)+' pixels')\n",
    "\n",
    "if bands[\"450\"]:\n",
    "    print(\"450$\\mu$m band:\")\n",
    "    print('\\t fitting '+ str(prior450.nsrc)+' sources \\n')\n",
    "    print('\\t using ' +  str(prior450.snpix)+' pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting, the prior classes need to take the PSF and calculate how muich each source contributes to each pixel. This process provides what we call a pointing matrix. Lets calculate the pointing matrix for each prior class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bands[\"850\"]:\n",
    "    prior850.get_pointing_matrix()\n",
    "\n",
    "if bands[\"450\"]:\n",
    "    prior450.get_pointing_matrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default prior on flux is a uniform distribution, with a minimum and maximum of 0.00 and 1000.0 $\\mathrm{mJy}$ respectively for each source. running the function upper_lim _map resets the upper limit to the maximum flux value (plus a 5 sigma Background value) found in the map in which the source makes a contribution to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bands[\"850\"]:\n",
    "    prior850.upper_lim_map()\n",
    "\n",
    "if bands[\"450\"]:\n",
    "    prior450.upper_lim_map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit using the XID+ interface to pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/XID+SCUBA2 found. Reusing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from xidplus.stan_fit import SCUBA2\n",
    "\n",
    "if bands[\"850\"]:\n",
    "    fit850=SCUBA2.single_band(prior850,iter=1000)\n",
    "\n",
    "if bands[\"450\"]:\n",
    "    fit450=SCUBA2.single_band(prior450,iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the posterior class with the fit object from pystan, and save alongside the prior classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bands[\"850\"]:\n",
    "    posterior850=xidplus.posterior_stan(fit850,[prior850])\n",
    "    xidplus.save([prior850],posterior850,imfolder+'test-850-mf')\n",
    "\n",
    "if bands[\"450\"]:\n",
    "    posterior=xidplus.posertior_stan(fit450,[prior450])\n",
    "    xidplus.save([prior450],posterior450,imfolder+'test-450')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
